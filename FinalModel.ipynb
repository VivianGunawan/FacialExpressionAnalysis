{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, Input\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import expanduser, exists, join\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a csv file with a list of image paths, picking 20 random images for each video\n",
    "start = time.time()\n",
    "\n",
    "labels = pd.read_csv('../csv_files/labelsfolds2019.csv')\n",
    "\n",
    "videos = []\n",
    "paths = []\n",
    "categories = []\n",
    "numbers = []\n",
    "fold_num = []\n",
    "\n",
    "i = 1\n",
    "# get a list of all the directories which contain images for a certain year\n",
    "for folder in glob.glob(\"../299_verified_2019/*\"):\n",
    "\n",
    "    video = folder\n",
    "    video = video.replace(\"../299_verified_2019/\", \"\")\n",
    "    video_path = video + \".mp4\"\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    # go through every each for each video directory\n",
    "    for image in glob.glob(f\"{folder}/*jpg\"):\n",
    "        image_list.append(image)\n",
    "    \n",
    "    # get 20 random images from each directory\n",
    "    if len(image_list) <= 20:\n",
    "        image_list_short = image_list\n",
    "    else:\n",
    "        image_list_short = random.sample(image_list, 20)\n",
    "\n",
    "#     for image in glob.glob(f\"{folder}/*.jpg\"):\n",
    "\n",
    "    # save the image path, the label, and the fold number\n",
    "    for image in image_list_short:\n",
    "        \n",
    "        file = labels[labels['Filename'] == video_path]\n",
    "        fold = file['TestFold']\n",
    "        fold = list(fold)[0]\n",
    "        \n",
    "        image = image.replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        category = file['Label']\n",
    "        category = list(category)[0]\n",
    "        \n",
    "        \n",
    "        videos.append(video)\n",
    "        paths.append(image)\n",
    "        categories.append(category)\n",
    "        fold_num.append(fold)\n",
    "        \n",
    "        if category == 'Positive':\n",
    "            numbers.append(2)\n",
    "        elif category == 'Neutral':\n",
    "            numbers.append(1)\n",
    "        else:\n",
    "            numbers.append(0)\n",
    "        \n",
    "\n",
    "    current_time = time.time()\n",
    "    if i % 100 == 0:\n",
    "        duration = current_time - start\n",
    "        print(f\"{i} videos processed\")\n",
    "        print(f\"Time elapsed: {duration}\")\n",
    "        time_per_video = duration/i\n",
    "        remaining_videos = 1320 - i\n",
    "        estimated_time_remaining = time_per_video*remaining_videos\n",
    "        print(f\"Estimated time remaining: {estimated_time_remaining}\")\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "dictionary = {\"Video\" : videos, \"Path\": paths, \"Category\": categories, \"Category_Numbers\" : numbers, \"Fold\" : fold_num}\n",
    "\n",
    "data = pd.DataFrame.from_dict(dictionary)\n",
    "\n",
    "data.to_csv(\"../csv_files/299_2019_paths_folds_20.csv\", index = False)\n",
    "\n",
    "print(\"Video length: \", len(videos))\n",
    "print(\"Path length: \", len(paths))\n",
    "print(\"Category Length: \", len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to visualize the results of the model\n",
    "# confusion matrix functions taken from the programming 1 assignment (neural network)\n",
    "def getConfusionMatrix(YTrue, YPredict):\n",
    "    \"\"\"\n",
    "    Computes the confusion matrix.\n",
    "    Parameters\n",
    "    ----------\n",
    "    YTrue : numpy array\n",
    "        This array contains the ground truth.\n",
    "    YPredict : numpy array\n",
    "        This array contains the predictions.\n",
    "    Returns\n",
    "    CM : numpy matrix\n",
    "        The confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    dim = int(np.max(YTrue)) + 1\n",
    "\n",
    "    CM = np.zeros((dim, dim))\n",
    "    for t, p in zip(YTrue, YPredict):\n",
    "        CM[p][int(t)] += 1\n",
    "        \n",
    "    return CM\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label')\n",
    "    \n",
    "# plotting history of model taken from this source: https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image paths with the relevant label and fold information\n",
    "data = pd.read_csv(\"../csv_files/299_2019_paths_folds_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [.0001]\n",
    "\n",
    "fold_numbers = list(range(0,5))\n",
    "\n",
    "image_size = (299, 299)\n",
    "batch_size = 32\n",
    "\n",
    "class_weights = {0: 2, 1 : 1, 2 : 1.8}\n",
    "\n",
    "all_preds = []\n",
    "all_history = []\n",
    "for lr in learning_rates:\n",
    "    for fold_num in fold_numbers:\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # separate the data into training and test set based on folds\n",
    "        train_fold = data[data['Fold'] != fold_num]\n",
    "        train_fold = train_fold.copy()\n",
    "\n",
    "        test_fold = data[data['Fold'] == fold_num]\n",
    "        test_fold = test_fold.copy()\n",
    "\n",
    "        # generators taken from: https://www.kaggle.com/careyai/inceptionv3-full-pretrained-model-instructions\n",
    "        datagen = ImageDataGenerator(rescale=1. / 255., validation_split=0.25,)\n",
    "\n",
    "        # Train generator\n",
    "        train_generator = datagen.flow_from_dataframe(\n",
    "            dataframe=train_fold,\n",
    "            x_col=\"Path\",\n",
    "            y_col=\"Category\",\n",
    "            subset=\"training\",\n",
    "            batch_size=batch_size,\n",
    "            seed=8,\n",
    "            shuffle=True,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=image_size)\n",
    "\n",
    "        print('Class indices: ', train_generator.class_indices)\n",
    "        # Validation generator\n",
    "        val_generator = datagen.flow_from_dataframe(\n",
    "            dataframe=train_fold,\n",
    "            x_col=\"Path\",\n",
    "            y_col=\"Category\",\n",
    "            subset=\"validation\",\n",
    "            batch_size=batch_size,\n",
    "            seed=8,\n",
    "            shuffle=True,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=image_size)\n",
    "        print('Class indices: ', val_generator.class_indices)\n",
    "\n",
    "        # Test generator\n",
    "        test_datagen = ImageDataGenerator(rescale=1. / 255.)\n",
    "        test_generator = test_datagen.flow_from_dataframe(\n",
    "            dataframe=test_fold,\n",
    "            x_col=\"Path\",\n",
    "            y_col='Category',\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=batch_size,\n",
    "            seed=8,\n",
    "            shuffle=False,\n",
    "            target_size=image_size)\n",
    "\n",
    "\n",
    "        # model taken from the following source:\n",
    "        # https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/\n",
    "        model = Sequential()\n",
    "\n",
    "        #1st convolution layer\n",
    "        model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(299,299,3)))\n",
    "        model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "        #2nd convolution layer\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "        #3rd convolution layer\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        #fully connected neural networks\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "        # compile the model\n",
    "        model.compile(Adam(lr=lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'],\n",
    "                     )\n",
    "        # print the model summary\n",
    "        model.summary()\n",
    "        \n",
    "        # fit the model\n",
    "        history = model.fit(train_generator,\n",
    "                    steps_per_epoch = 100,\n",
    "#                             validation_data = test_generator,\n",
    "#                             validation_steps = 20,\n",
    "                            epochs = 10,\n",
    "                            verbose = 1,\n",
    "                            workers = 8,\n",
    "                            use_multiprocessing = True)\n",
    "\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        all_history.append(history)\n",
    "\n",
    "        # run the model on the test fold\n",
    "        preds = model.predict(test_generator,\n",
    "                             workers = 8,\n",
    "                             use_multiprocessing = True)\n",
    "        \n",
    "        # get the largest probability value for each entry\n",
    "        pred_array = []\n",
    "        for pred in preds:\n",
    "            guess = np.argmax(pred)\n",
    "            pred_array.append(guess)\n",
    "\n",
    "        all_preds.append(pred_array)\n",
    "\n",
    "        # generate and plot the confusion matrix\n",
    "        CM = getConfusionMatrix(test_fold['Category_Numbers'], pred_array)\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(CM, classes=['0', '1', '2'], title='Confusion matrix')\n",
    "        plt.show()\n",
    "\n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        print(f\"Fold #{fold_num} took {duration} seconds to complete\")\n",
    "        print(\"Learning rate: \", lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
